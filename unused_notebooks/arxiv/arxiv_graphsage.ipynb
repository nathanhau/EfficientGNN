{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "activation = nn.ReLU()\n",
    "epochs = 50\n",
    "batch_size = 10000\n",
    "lr = 0.02\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DglNodePropPredDataset('ogbn-arxiv', root='dataset/')\n",
    "g, labels = data[0]\n",
    "labels = labels[:, 0]\n",
    "g.ndata['label'] = labels\n",
    "g = dgl.add_reverse_edges(g)\n",
    "features = g.ndata['feat']\n",
    "idx_split = data.get_idx_split()\n",
    "train_mask = idx_split['train']\n",
    "val_mask = idx_split['valid']\n",
    "test_mask = idx_split['test']\n",
    "in_feats = features.shape[1]\n",
    "n_classes = (labels.max() + 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=dgl.dataloading.NeighborSampler([4, 4])\n",
    "train_dataloader = dgl.dataloading.DataLoader(\n",
    "    g, train_mask, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")\n",
    "valid_dataloader = dgl.dataloading.DataLoader(\n",
    "    g, val_mask, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, activation):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = dgl.nn.SAGEConv(in_feats, n_hidden, 'mean')\n",
    "        self.conv2 = dgl.nn.SAGEConv(n_hidden, n_classes, 'mean')\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[:mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = self.activation(h)\n",
    "        h_dst = h[:mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(in_feats, 16, n_classes, activation)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (input_nodes, output_nodes, blocks) in enumerate(dataloader):\n",
    "            inputs = blocks[0].srcdata['feat']\n",
    "            labels = blocks[-1].dstdata['label']\n",
    "            predictions = model(blocks, inputs)\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            acc = torch.sum(predictions.argmax(1) == labels).item() / len(labels)\n",
    "            return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, features, labels, train_mask, val_mask, epochs, batch_size, lr, loss_fn, weight_decay):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for step, (input_nodes, output_nodes, blocks) in enumerate(train_dataloader):\n",
    "            inputs = blocks[0].srcdata['feat']\n",
    "            labels = blocks[-1].dstdata['label']\n",
    "            logits = model(blocks, inputs)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss, acc = test(valid_dataloader)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f}'.format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Files\\Coding\\ml\\EfficientGNN\\venv\\lib\\site-packages\\dgl\\dataloading\\dataloader.py:859: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(f'Dataloader CPU affinity opt is not enabled, consider switching it on '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 2.5287 | Accuracy 0.3345\n",
      "Epoch 00010 | Loss 1.3079 | Accuracy 0.6152\n",
      "Epoch 00020 | Loss 1.2636 | Accuracy 0.6162\n",
      "Epoch 00030 | Loss 1.2430 | Accuracy 0.6245\n",
      "Epoch 00040 | Loss 1.2324 | Accuracy 0.6299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.2256), 0.6367)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, g, features, labels, train_mask, val_mask, epochs, batch_size, lr, loss_fn, weight_decay)\n",
    "test(valid_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53236ea3850ed19be974e6741f9c7a7506ed085a4abb6419de9917a82e4ffe4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
